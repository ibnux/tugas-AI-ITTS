# ğŸ¤– Setup Ollama + PDF Chat

## Alur Cara Kerja

```
PDF Files â†’ PyMuPDFReader â†’ LlamaIndex â†’ Vector Index â†’ Stored
                                                            â†“
User Question â†’ Vector Search (Retrieve) â†’ Ollama LLM (Generate) â†’ Natural Answer
```

## Step-by-Step Setup

### 1ï¸âƒ£ Install Ollama

**Option A: Mac dengan Homebrew**
```bash
brew install ollama
```

**Option B: Download Manual**
Visit https://ollama.ai dan download untuk Mac/Linux/Windows

### 3ï¸âƒ£ Pull Model (Di Terminal Baru)

```bash

# Recommended:  llama3.2:1b untuk macbook pro M2
ollama pull  llama3.2:1b

# Atau alternative:
ollama pull mistral        #  Mistral (cepat dan berkualitas)
ollama pull neural-chat    # Lebih kecil, lebih cepat
ollama pull llama2         # Lebih besar, lebih accurate
```

Tunggu sampai selesai (bisa 5-15 menit tergantung koneksi).

### 2ï¸âƒ£ Jalankan Ollama Server

```bash
ollama serve
```

Output akan seperti:
```
pulling manifest
pulling 1d7ad209...
...
success
```

**JANGAN CLOSE TERMINAL INI!** Biarkan Ollama terus berjalan.


### 4ï¸âƒ£ Verify Setup

```bash
# Test Ollama berhasil
curl http://localhost:11434/api/tags

# Output akan menunjukkan model yang sudah ter-install
```

### 5ï¸âƒ£ Build Index dari PDF (Jika belum)

```bash
python build_index.py
```

Output:
```
âœ… SUCCESS! Index saved to ./storage/
```

### 6ï¸âƒ£ Jalankan Chat App

```bash
streamlit run app.py
```

Browser otomatis terbuka

---

## ğŸš€ Cara Pakai

1. **Ketik pertanyaan** di chat input
2. **Ollama akan:**
   - Retrieve dokumen relevan dari index
   - Membaca isi dokumen
   - Generate jawaban natural
3. **Dapatkan jawaban** dalam format conversational

### Contoh:

**User:** "Bagaimana prosedur wisuda di ITTS?"

**Ollama:** 
```
Berdasarkan dokumen akademik ITTS, prosedur wisuda melibatkan beberapa tahap:

1. Pertama, mahasiswa harus memastikan semua tunggakan akademik dan keuangan 
sudah lunas.

2. Kemudian, mendaftar ke bagian akademik dengan melengkapi semua dokumen 
yang diperlukan.

3. Setelah itu, mengikuti acara wisuda sesuai jadwal yang sudah ditentukan.

4. Terakhir, pengambilan ijazah dan transkrip nilai di bagian akademik.

Sumber: Buku_Pedoman_Akademik_2025_2026.pdf
```

---

## ğŸ”§ Troubleshooting

### âŒ "Connection refused"
```
Pastikan Ollama server running:
ollama serve

(Di terminal yang berbeda)
```

### âŒ "Model not found"
```
Pull model lagi:
ollama pull mistral
```

### âŒ Jawaban lambat
```
Model Mistral mungkin sudah cukup cepat.
Jika masih lambat, coba yang lebih kecil:
ollama pull neural-chat
```

Lalu update di app.py:
```python
OLLAMA_MODEL = "neural-chat"
```

---

## ğŸ“Š Model Comparison

| Model | Size | Speed | Quality | RAM |
|-------|------|-------|---------|-----|
| neural-chat | 4 GB | Fast âš¡ | Good | 8 GB |
| mistral | 5 GB | Fast | Great | 12 GB |
| llama2 | 7 GB | Medium | Excellent | 16 GB |

---

## ğŸ’¡ Tips

**Best Practice:**
- Keep Ollama running in background
- Use specific questions for better answers
- Chat history tersimpan per session

**Performance:**
- First response lebih lambat (model loading)
- Subsequent responses lebih cepat
- Jawaban bisa 5-30 detik tergantung model

---

## ğŸ‰ Setup Complete!

Semuanya sudah siap:
- âœ… PDF indexed
- âœ… App configured  
- âœ… Ollama integrated

**Mulai chat:** `streamlit run app.py`
